# Developer notes

!!! note
    This page needs to be cleaned up.

This page contains useful notes for developers and contributors.


## Manage script

A bash script `manage.sh` script at the repository root provides commands for build, test, doc generation, and so on.

| Command | Description |
| ---- | --- |
| `./manage.sh build` | recompile the library |
| `./manage.sh doc` | rebuild the doc website in `site/` |
| `./manage.sh docs` | serve the website on `localhost:8000` |
| `./manage.sh cython` | update the Cython binding definitions and recompile the Python module |
| `./manage.sh test test_array_` | run all tests starting with the given string |


## Documentation building

We use mkdocs, with material theme, and several markdown, theme, and mkdocs plugins. See `mkdocs.yml`. The site is generated in the `site/` subfolder. We use GitHub Pages to serve the website.

Several parts of the documentation are auto-generated, via mkdocs hooks implemented in `utils/hooks.py`. Building the documentation requires Python dependencies found in `utils/requirements-build.txt`. In particular, we use the `mkdocs-simple-hooks` package to make it possible to use custom Python functions as mkdocs plugin hooks.

* **API documentation**: the list of functions to document is found in the `docs/api/*.md` files. At documentation build time, the API doc generation script (`utils/gendoc.py`) parses the library header files, extracts the doxygen docstrings, and inserts them at the right places in the API documentation pages.
* **Enumerations**: the documentation file `api/enums.md` contains a list of headers of enumerations. A script parses the enums in the library header files and inserts them in this file, at documentation build time.
* **Colormaps**: colormaps definitions are saved in a CSV file in `data/textures/color_texture.csv`. This file is parsed by `utils/export_colormap.py` and the table of all colormaps is automatically generated, using NumPy and Pillow to generate base64-encoded individual colormap images. The table is inserted at the end of `docs/user/colormaps.md`.
* **Visual documentation**: visuals are documented manually. The screenshots are generated by the `builtin_visual.c` unit tests.
* **Graphics documentation**: the item, vertex, params structure fields are automatically generated by a script that parses the relevant struct definitions in the library header files.
* **Code snippets and screenshots**: the documentation build script parses `<!-- CODE_PYTHON path/to/file.py -->` and `<!-- IMAGE path/to/image.png -->` in documentation sources and inserts the code file contents, or the image.

!!! note
    The API doc generation uses joblib to save time when live-regenerating the documentation. However the cache in `utils/.joblib` must be deleted (so that it's automatically recreated) whenever the Datoviz code/API changes. Otherwise, the API doc generation script may fail.


## Shaders

All shaders include common GLSL files found in `include/datoviz/glsl/`. This path must be passed to the `glslc` command with the `-I` flag. This is what the CMake script is using.

Compiled shaders of the builtin graphics are bundled into the library, using a special CMake command. The binary contents of the SPIR-V-compiled shaders are integrated in `build/_shaders.c`, which is compiled along with the other C source files of the library.



## Dependencies


### Dear ImGUI

Datoviz integrates Dear ImGUI via a git submodule ([fork](https://github.com/datoviz/imgui) in the Datoviz GitHub organization). There's a custom branch based on `master`, but which an additional [patch](https://github.com/martty/imgui/commit/f1f948bea715754ad5e83d4dd9f928aecb4ed1d3) applied to it in order to support creating GUIs with integrated Datoviz canvases (not yet implemented).



## C formatting

We use clang format to automatically format all C source files. The rules are defined in `.clang-format`.

[We follow loosely this coding guide.](https://developer.lsst.io/cpp/api-docs.html)


## Command-line tool

Datoviz includes an executable that implements test and examples, implemented in the `cli/` subfolder.


## Shaders and binary resource embedding

Important binary resources such as SPIR-V compiled shaders of all included graphics, and the colormap texture, are built directly into the compiled library object. A cmake script loads these files and generates big `build/_colortex.c` and `build/_shaders.c` files, which are then compiled and linked into the library.



## Instructions for building the Python bindings

On Linux, go to the Datoviz root folder, and do `./manage.sh cython`.

This script essentially does `python3 setup.py build_ext -i` after automatically updating the Cython low-level wrapper with a Python script.



## Making a pip package

Goal: make Datoviz easily installable with `pip install datoviz` or `conda install datoviz`.

This is challenging given that Datoviz is written in C, has some dependencies, and that the Python bindings use Cython.

This is a work in progress.


### Linux

* The first option I've tried is to make a manylinux pip wheel. This wheel is supposed to work on a large variety of relatively modern Linux distributions.
* A major complication is that the built Cython package depends on the compiled C library (dynamic linking to libdatoviz) and has other system dependencies (Vulkan, etc).
* The only option to build a manylinux is basically to use Docker, because a manylinux wheel needs to be built on an old minimal Linux distribution.

Here are the steps I've followed so far:

1. I start from the `quay.io/pypa/manylinux_2_24_x86_64` Docker image (this Docker image is based on Debian, all the others seem to be based on CentOS, but Vulkan doesn't work well on old CentOS distributions).
2. In the `Dockerfile_wheel` file, I install a few apt packages needed for building (related to X11, ninja, etc), and I install Vulkan.
3. In the Docker image, I also install the Python dependencies.
4. The Docker image contains the auditwheel tool provided by the PyPA. This tool allows to "repair" a wheel on Linux by integrating all dependencies in it so as to avoid compatibility issues between different variants of Linux distribution. However, this tools misses an option to select the included dependencies. It includes libraries such as libvulkan which should *not* be bundled in the wheel, they are supposed to be in the client system (GPU driver) in order to access the GPU. There are apparently other such libraries that should not be included, but I haven't had time to find out which exactly. So I've submitted a [patch](https://github.com/pypa/auditwheel/pull/310) to auditwheel in order to implement `--include` and `--exclude` command-line options to auditwheel. The Docker image installs the patched auditwheel tool, that will be used at the end of the process (see below).
5. Now, to create the manylinux wheel, one must create a Docker container, mount the Datoviz root directory in it, and run a special script, `wheel.sh`.
6. Here's what this script does (it runs in the Docker container). First, it builds the Datoviz C library in the `build_wheel` subfolder.
7. Then, it copies the headers, the build directory, and the Cython source files in a temporary directory in the container so as to avoid polluting the main Datoviz directory.
8. Next, it builds the Cython package and it creates a wheel.
9. The wheel doesn't include any dependency so it will *not* work on another system.
10. Therefore, we use the patched auditwheel tool to bundle libdatoviz and a few other needed dependencies (note: we'll have to test the wheel on various fresh distributions to ensure it works on as many systems as possible).
11. Finally, it copies the repaired wheel into `bindings/cython/dist`. This wheel is theoretically uploadable to PyPI, [*but* we have to make sure it works on different systems first](https://github.com/pypa/auditwheel/pull/310#issuecomment-849858348). We may run into issues and we may have to include more dependencies in the auditwheel repair process. So for now, we will only upload the wheel on GitHub.



## Environment variables

| Environment variable              | Description                                           |
|-----------------------------------|-------------------------------------------------------|
| `DVZ_FPS=1`                       | Show the number of frames per second                  |
| `DVZ_LOG_LEVEL=0`                 | Logging level                                         |


* **Vertical synchronization** is activated by default. The refresh rate is typically limited to 60 FPS. Deactivating it (which is automatic when using `DVZ_FPS=1`) leads to the event loop running as fast as possible, which is useful for benchmarking. It may lead to high CPU and GPU utilization, whereas vertical synchronization is typically light on CPU cycles. Note also that user interaction seems laggy when vertical synchronization is active (the default). When it comes to GUI interaction (mouse movements, drag and drop, and so on), we're used to lags lower than 10 milliseconds, which a frame rate of 60 FPS cannot achieve.
* **Logging levels**: 0=trace, 1=debug, 2=info, 3=warning, 4=error
* **DPI scaling factor**: Datoviz natively supports DPI scaling for linewidths, font size, axes, etc. Since automatic cross-platform DPI detection does not seem reliable, Datoviz simply uses sensible defaults but provides an easy way for the user to increase or decrease the DPI via this environment variable. This is useful on high-DPI/Retina monitors.
